{
  "augment_smiles": false,
  "smiles_canonical": false,
  "smiles_start_stop_token": true,
  "smiles_padding_length": 1024,
  "protein_padding_length": 8192,
  "dense_hidden_sizes": [20],
  "activation_fn": "relu",
  "dropout": 0.3,
  "batch_norm": true,
  "batch_size": 1024,
  "lr": 0.001,
  "epochs": 200,
  "save_model": 25,
  "smiles_vocabulary_size": 274,
  "protein_vocabulary_size": 32
}